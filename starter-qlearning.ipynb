{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4723b432-2bb3-44f9-8cf5-3684730f3f34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "from pettingzoo.classic import connect_four_v3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "from IPython.display import clear_output\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "606cb4a3-bf34-4b86-9b98-2abb342b10fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 7, 2)\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "[1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Initialisation de l'environnement\n",
    "env = connect_four_v3.env(render_mode=\"rgb_array\")\n",
    "\n",
    "env.reset()\n",
    "\n",
    "# The main difference with the standard gym api is the way the environment is queried. The `step` method return `None`. To get the data on the environment, use the `last` method\n",
    "state, reward, terminated, truncated, info = env.last()\n",
    "\n",
    "# state is a dictionary with two keys: observation and action_mask\n",
    "print(\n",
    "    state[\"observation\"].shape\n",
    ")  # Observation is a numpy array with three coordinates, indicating the positions of the pieces of of player 0 and 1 on the the board\n",
    "print(state[\"observation\"][:, :, 0])  # Where the pieces of player 0 are\n",
    "print(state[\"observation\"][:, :, 1])  # Where the pieces of player 1 are\n",
    "\n",
    "print(state[\"action_mask\"])  # an array showing whether the actions are legal or nots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9ba14e-0488-4cfb-8b96-0fc5c7f034dc",
   "metadata": {},
   "source": [
    "<h4>Brouillon<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6fcebe2e-48fa-44dc-9086-2e2c62fa73b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 7, 2)\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]]\n",
      "[1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#env.reset()\n",
    "env.step(3)\n",
    "\n",
    "state, reward, terminated, truncated, info = env.last()\n",
    "\n",
    "print(\n",
    "    state[\"observation\"].shape\n",
    ") \n",
    "print(state[\"observation\"][:, :, 0])  \n",
    "print(state[\"observation\"][:, :, 1])  \n",
    "\n",
    "print(state[\"action_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3de65eb5-72ca-4bb4-9965-0371beee81ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab=state[\"observation\"][:, :, 1]\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cbf51b94-30cb-4db2-a6c1-0fa636d014c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "act=3\n",
    "for i in range(height):\n",
    "    if state[\"observation\"][:, act, 1][i] != 0:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c61c737-2b8f-4af1-8012-4cb386f9244a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, reward, terminated, truncated, info = env.last()\n",
    "reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8052922f-30ff-4a5b-a51f-45a0645c1783",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Local view of the game (the last move)<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaef7c5b-1fef-4c69-ac7b-0f8b30488917",
   "metadata": {},
   "source": [
    "Première approche (naive) : Q-Learning avec matrice d'état = Toutes les positions de la grille (**état d'un agent= coordonnées du dernier coût joué par ce même agent**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d93e85b8-1cd3-48ba-a020-5ee96f71de00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[\"observation\"][4, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa138fee-4988-4865-8c09-f8eb5c0525cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Dimensions du tableau\n",
    "height=6\n",
    "width=7\n",
    "\n",
    "#Fonction qui initialise la matrice Q\n",
    "def initialize_Q(): #Initialise la matrice Q (que des zéros)\n",
    "    return np.zeros((height, width, width)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afeb455a-7d47-4602-a3cd-442bd1d6ccce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, _id, Q, rng=None): \n",
    "        self.name = 'Player '+str(_id)\n",
    "        self.Q=initialize_Q()\n",
    "        self.st=None #Etat\n",
    "        self._id=_id #Identifiant\n",
    "        \n",
    "    def get_action(self, epsilon=None):\n",
    "        if (random.uniform(0,1)<epsilon) or (self.st is None): #Exploration ou premier coupde la partie\n",
    "            action=random.randint(0,6)  \n",
    "        else:\n",
    "            (x,y)=self.st\n",
    "            Q=self.Q\n",
    "            action=np.argmax(Q[x,y]) #On choisit la meilleure action parmi celles qu'il peut jouer (meilleure dans le sens maximise Q)\n",
    "            return action\n",
    "    def highest_not_null(self, action, obs): #Fonction auxiliaire à la fonction pour déterminer l'état\n",
    "        _id=self._id\n",
    "        for i in range(height):\n",
    "            if obs[\"observation\"][:, act, _id][i] != 0: \n",
    "                return i\n",
    "\n",
    "    def update_state(self,action, obs): #Fonction qui update l'état du joueur (trouve en fait le dernier coup joué)\n",
    "        y=action\n",
    "        x=self.highest_not_null(action, obs)\n",
    "        self.st=(x,y)\n",
    "    def update_Q(self, last_state, action): #fonction qui update Q selon \n",
    "        next_action=self.get_action(epsilon=0.0)\n",
    "        (a,b)=self.st\n",
    "        (x,y)=last_state\n",
    "        Q=self.Q\n",
    "        self.Q[x,y][action]=Q[x,y][action] + alpha*(r + gamma*Q[a,b][next_action]-Q[x,y][action])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bc27dc0-9f82-4514-8f81-ed7ce4878753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr=np.array([[[0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.]],\n",
    "\n",
    "       [[0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.]],\n",
    "\n",
    "       [[0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 7., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.]],\n",
    "\n",
    "       [[0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.]],\n",
    "\n",
    "       [[0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.]],\n",
    "\n",
    "       [[0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d6cbd0a-faa3-4526-b5b6-2b6e0909747d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 7., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[2,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98cfbec2-3a6c-4015-84ac-979e0d2f3281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def play_game(env, agent0, agent1, alpha, gamma ,r ,e, display=False): #e epsilon coeff d'exploration\n",
    "    done = False\n",
    "    env.reset()\n",
    "    obs, _, _, _, _ = env.last()\n",
    "    while not done:\n",
    "        for i, agent in enumerate([agent0, agent1]):\n",
    "            last_state=agent.st\n",
    "            action = agent.get_action(obs, epsilon=e) #Epsilon = taux d'exploration\n",
    "            env.step(action) #Préciser à l'environnement pettingZoo que l'action prise\n",
    "            obs, reward, terminated, _, _ = env.last()\n",
    "            agent.update_state(action, obs) #Mise à jour de l'état de l'agent\n",
    "            if display:\n",
    "                clear_output(wait=True)\n",
    "                plt.imshow(env.render())\n",
    "                plt.show()\n",
    "            done = terminated #Déroulement fini\n",
    "            #update Q\n",
    "            agent.update_Q(last_state, action)\n",
    "            \n",
    "            if np.sum(obs[\"action_mask\"]) == 0:\n",
    "                if display: \n",
    "                    print('Draw')\n",
    "                return 0.5\n",
    "            if done:\n",
    "                if display:\n",
    "                    print(f\"Player {i}: {agent.name} won\")\n",
    "                    print(obs['observation'][:, :, 0]- obs['observation'][:, :, 1])\n",
    "                return i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
